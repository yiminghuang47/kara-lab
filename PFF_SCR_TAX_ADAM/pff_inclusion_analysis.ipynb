{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9706e858",
   "metadata": {},
   "source": [
    "The purpose of this code is to quantify the nuclei, the size and number of synuclein inclusions, and the inclusion areas in the lysotracker experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30d31b",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a15984f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.morphology import remove_small_objects, binary_dilation, disk, binary_closing\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import exposure\n",
    "import czifile\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_image(image):\n",
    "    \"\"\"Display image\"\"\"\n",
    "    io.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43beac27",
   "metadata": {},
   "source": [
    "Define Sub Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df11f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_image_paths(folder):\n",
    "    \"\"\"Extract all image file paths from the specified folder.\"\"\"\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "def read_czi_image(image_path, dapi_channel_idx=1, green_channel_idx=0):\n",
    "    \"\"\"Load and extract dapi, green, and red channel data from a CZI file.\"\"\"\n",
    "    czi_file = czifile.CziFile(image_path)\n",
    "    czi_data = czi_file.asarray()\n",
    "    dapi_channel_data = np.squeeze(czi_data[:, :, dapi_channel_idx, :, :, :])\n",
    "    \n",
    "    green_channel_data = np.squeeze(czi_data[:, :, green_channel_idx, :, :, :])\n",
    "    \n",
    "    return dapi_channel_data, green_channel_data\n",
    "\n",
    "\n",
    "def otsu_thresholding(channel):\n",
    "    \"\"\"Apply Otsu's thresholding and morphological closing to the channel.\"\"\"\n",
    "    threshold_value = threshold_otsu(channel)\n",
    "    binary_image = channel > threshold_value\n",
    "    show_image(binary_image)\n",
    "    closed_image = binary_closing(binary_image, disk(3))\n",
    "    labeled_image = label(closed_image)\n",
    "    return labeled_image\n",
    "\n",
    "def calculate_surface_area(labeled_image, channel):\n",
    "    \"\"\"Calculate the total surface area for labeled regions.\"\"\"\n",
    "    props = regionprops(labeled_image, channel)\n",
    "    return sum(prop.area for prop in props)\n",
    "\n",
    "def preprocess_dapi_channel(dapi_channel):\n",
    "    \"\"\"Preprocess the DAPI channel for nuclei quantification.\"\"\"\n",
    "    blurred_dapi = gaussian(dapi_channel, sigma=2)\n",
    "    threshold_value = threshold_otsu(blurred_dapi)\n",
    "    binary_image = blurred_dapi > threshold_value\n",
    "    show_image(binary_image)\n",
    "    cleaned_image = remove_small_objects(binary_image, min_size=400)\n",
    "    merged_image = binary_dilation(cleaned_image, footprint=disk(5))\n",
    "    labeled_image = label(merged_image)\n",
    "    return labeled_image\n",
    "\n",
    "def count_nuclei(labeled_image):\n",
    "    \"\"\"Count the number of nuclei in the labeled image.\"\"\"\n",
    "    return len(np.unique(labeled_image)) - 1\n",
    "\n",
    "def preprocess_green_channel(green_channel):\n",
    "    \"\"\"Preprocess the green channel for inclusion quantification.\"\"\"\n",
    "    confocal_img = exposure.adjust_sigmoid(green_channel, cutoff=0.25)\n",
    "    confocal_img = (confocal_img - confocal_img.min()) / (confocal_img.max() - confocal_img.min())\n",
    "    return confocal_img\n",
    "\n",
    "def threshold_inclusions(confocal_img):\n",
    "    \"\"\"Threshold the preprocessed green channel to segment inclusions.\"\"\"\n",
    "    threshold = 0.95\n",
    "    binary_image = confocal_img > threshold\n",
    "    show_image(binary_image)\n",
    "    labeled_image = label(binary_image)\n",
    "    return labeled_image\n",
    "\n",
    "def measure_inclusion_sizes(labeled_image, confocal_img):\n",
    "    \"\"\"Measure the sizes of inclusions.\"\"\"\n",
    "    props = regionprops(labeled_image, confocal_img)\n",
    "    sizes = [prop.area for prop in props]\n",
    "    return [size for size in sizes if size > 10]\n",
    "\n",
    "def add_to_dataframe(sizes_df_new, sizes, path):\n",
    "    \"\"\"Add sizes of inclusions to the DataFrame.\"\"\"\n",
    "    sizes_df_add = pd.DataFrame(sizes, columns=[f'image {path}'])\n",
    "    if sizes_df_new is None:\n",
    "        return sizes_df_add\n",
    "    else:\n",
    "        return pd.concat([sizes_df_new, sizes_df_add], axis=1)\n",
    "\n",
    "def calculate_metrics(number_of_nuclei_list, sizes_df_new):\n",
    "    \"\"\"Calculate additional metrics and return the second DataFrame.\"\"\"\n",
    "    sizes_df_new_nuclei = sizes_df_new.transpose()\n",
    "    number_of_inclusions = sizes_df_new_nuclei.count(axis=1)\n",
    "    average_number_of_inclusions = number_of_inclusions / np.array(number_of_nuclei_list)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"number_of_inclusions\": number_of_inclusions,\n",
    "        \"Number_of_Nuclei\": number_of_nuclei_list,\n",
    "        \"Average_Number_of_Inclusions_per_Cell\": average_number_of_inclusions,\n",
    "    })\n",
    "\n",
    "def calculate_sizes(sizes_df_new):\n",
    "    \"\"\"Return a Dataframe consisting of the sizes of individual inclusion\"\"\"\n",
    "    sizes_df_new = sizes_df_new.transpose()\n",
    "\n",
    "    # for file_name in sizes_df_new.index:\n",
    "    #     for count in sizes_df_new.columns:\n",
    "    #         inclusion_size = sizes_df_new.loc[file_name,count]\n",
    "    #         if math.isnan(inclusion_size):\n",
    "    #             continue\n",
    "    #         data.append({\"file_name\":file_name,\"inclusion_number\":count,\"inclusion_size\":inclusion_size})\n",
    "\n",
    "    data = [\n",
    "        {\"file_name\": file_name, \"inclusion_number\": count, \"inclusion_size\": size}\n",
    "        for file_name in sizes_df_new.index\n",
    "        for count, size in sizes_df_new.loc[file_name].items()\n",
    "        if not math.isnan(size)\n",
    "    ] \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3f383",
   "metadata": {},
   "source": [
    "Define Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fcf244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(image_folder):\n",
    "    # Initialize lists to store results\n",
    "    number_of_nuclei_list = []\n",
    "    sizes_df_new = None\n",
    "\n",
    "    images_to_analyze = extract_image_paths(image_folder)\n",
    "\n",
    "    # Iterate over each image\n",
    "    for path in images_to_analyze:\n",
    "        # print(path)\n",
    "        dapi_channel, green_channel = read_czi_image(path)\n",
    "        \n",
    "        # Process DAPI channel for nuclei counting\n",
    "        labeled_image_dapi = preprocess_dapi_channel(dapi_channel)\n",
    "\n",
    "        n_nuclei = count_nuclei(labeled_image_dapi)\n",
    "        number_of_nuclei_list.append(n_nuclei)\n",
    "\n",
    "        # Process green channel for inclusion quantification\n",
    "        confocal_img = preprocess_green_channel(green_channel)\n",
    "        \n",
    "        labeled_image_inclusions = threshold_inclusions(confocal_img)\n",
    "        \n",
    "        \n",
    "        inclusion_sizes = measure_inclusion_sizes(labeled_image_inclusions, confocal_img)\n",
    "\n",
    "        # Add to DataFrame\n",
    "        sizes_df_new = add_to_dataframe(sizes_df_new, inclusion_sizes, os.path.basename(path))\n",
    "\n",
    "    # Calculate metrics and save results\n",
    "    date = '251024'\n",
    "    excel_2 = calculate_metrics(number_of_nuclei_list, sizes_df_new)\n",
    "    excel_2.to_excel(f\"PFF_Inclusion_Count_{date}.xlsx\")\n",
    "\n",
    "    excel_3 = calculate_sizes(sizes_df_new)\n",
    "    excel_3.to_excel(f\"PFF_Inclusion_Size_{date}.xlsx\",index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    image_folder = '251024_PFF_SCR_TAX_ADAM' # threshold = 0.95\n",
    "    \n",
    "    main(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc00f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999b002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
